{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=floatX=float32,device=gpu0,lib.cnmem=0.5\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=floatX=float32,device=gpu0,lib.cnmem=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1070 (CNMeM is enabled with initial size: 50.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import h5py\n",
    "import json\n",
    "import pandas as pd\n",
    "import scipy as scp\n",
    "import cv2\n",
    "import numpy as np \n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD\n",
    "# from deeplearningmodels.imagenet_utils import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copyfile\n",
    "import shutil\n",
    "from convnetfactory import ConvNetFactory\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from convnetfactory import ConvNetFactory, VGG_16\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minority_balance_dataframe_by_multiple_categorical_variables(df, var=['label']):\n",
    "    minority_class_combination_count = df.groupby(var).apply(lambda x: x.shape[0]).min()\n",
    "    df = df.groupby(var).apply(lambda x: x.sample(minority_class_combination_count)).drop(var, axis=1).reset_index().set_index('level_1')\n",
    "    df.sort_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "front-side    5246\n",
       "back-side     1084\n",
       "side           952\n",
       "front          512\n",
       "back           196\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare data\n",
    "\n",
    "EXCLUDE_LABELS = ['top','other','noclass']\n",
    "\n",
    "with open('labels.json', 'r') as labels:\n",
    "    labels = json.loads(labels.read())\n",
    "\n",
    "df_labels = pd.DataFrame(data={'label': list(labels.values()), 'file_name': list(labels.keys())})\n",
    "df_labels = df_labels[~df_labels.label.isin(EXCLUDE_LABELS)]\n",
    "# df_labels = df_labels[df_labels.label.isin(['front-side','back-side'])]\n",
    "\n",
    "\n",
    "df_labels.set_value(df_labels.index, 'is_train',True)\n",
    "\n",
    "# df_labels = minority_balance_dataframe_by_multiple_categorical_variables(df_labels)\n",
    "# \n",
    "\n",
    "train, test = train_test_split(df_labels, test_size = 0.2, stratify=df_labels.label)\n",
    "df_labels.set_value(train.index, 'is_train', True)\n",
    "df_labels.set_value(test.index, 'is_train', False)\n",
    "df_labels = df_labels.reindex_axis(sorted(df_labels.columns), axis=1)\n",
    "df_labels.label.value_counts()\n",
    "\n",
    "\n",
    "# train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create flow-from-directory-structure\n",
    "# cwd = os.getcwd()\n",
    "BASE_PATH = '/home/i008/googledrive/Projects/detect-good-car-picture/'\n",
    "EXP_NAME = 'exp'\n",
    "FULL_EXP_PATH = os.path.join(BASE_PATH, EXP_NAME)\n",
    "TRAIN_PATH = os.path.join(FULL_EXP_PATH, 'train')\n",
    "TEST_PATH = os.path.join(FULL_EXP_PATH, 'test')\n",
    "\n",
    "if os.path.exists(FULL_EXP_PATH):\n",
    "    shutil.rmtree(FULL_EXP_PATH)\n",
    "    \n",
    "os.makedirs(os.path.join(FULL_EXP_PATH))\n",
    "os.makedirs(os.path.join(FULL_EXP_PATH, 'train'))\n",
    "os.makedirs(os.path.join(FULL_EXP_PATH, 'test'))\n",
    "\n",
    "for label in df_labels.label.unique():\n",
    "    os.makedirs(os.path.join(FULL_EXP_PATH, 'train', label))\n",
    "    os.makedirs(os.path.join(FULL_EXP_PATH, 'test', label))       \n",
    "        \n",
    "for _, row in df_labels.iterrows():\n",
    "    path, is_train, label = row[0], row[1], row[2]\n",
    "    file_name = os.path.split(path)[-1]\n",
    "    if is_train:\n",
    "        copy_to = os.path.join(FULL_EXP_PATH, 'train', label, file_name)\n",
    "        copyfile(path, copy_to)\n",
    "    else:\n",
    "        copy_to = os.path.join(FULL_EXP_PATH, 'test', label, file_name)\n",
    "        copyfile(path, copy_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CHANNELS = 3\n",
    "target_size = (150, 150)\n",
    "imgRows = target_size[0]\n",
    "imgCols = target_size[1]\n",
    "N_CLASSES = len(df_labels.label.unique())\n",
    "c = (CHANNELS, 150, 150, 2)\n",
    "\n",
    "def create_model(img_rows, img_cols, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(3, img_rows, img_cols)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(*target_size, n_classes=N_CLASSES)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imd_train = image.ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True,\n",
    "#         vertical_flip=True\n",
    "\n",
    "# )\n",
    "\n",
    "# imd_test = image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# imd_train_flow = imd_train.flow_from_directory(TRAIN_PATH,\n",
    "#                                                color_mode='rgb',\n",
    "#                                                target_size=target_size,\n",
    "#                                                batch_size=32,\n",
    "#                                                class_mode='categorical'\n",
    "#                                               )\n",
    "# imd_test_flow = imd_test.flow_from_directory(TEST_PATH,\n",
    "#                                              color_mode='rgb',\n",
    "#                                              batch_size=32,\n",
    "#                                              class_mode='categorical',\n",
    "#                                              target_size=target_size)\n",
    "\n",
    "# training_history = model.fit_generator(\n",
    "#     imd_train_flow, \n",
    "#     validation_data=imd_test_flow, \n",
    "#     samples_per_epoch=df_labels[df_labels.is_train].shape[0], \n",
    "#     nb_epoch=30, \n",
    "#     verbose=True,\n",
    "#     nb_val_samples=200,\n",
    "#     class_weight={0: 1 , 1: 0.1808, 2: 0.38, 3: 0.03, 4: 0.2}\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# from keras import backend as K\n",
    "# IMAGE_ORDERING = 'tf'\n",
    "# IMAGENET_TARGET_SHAPE = (224, 224)\n",
    "# K.set_image_dim_ordering(IMAGE_ORDERING)\n",
    "# # images = [np.expand_dims(image.img_to_array(image.load_img(p, target_size=None)), axis=0) for p in df.file_name[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1598/1598 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76470588235294112"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imd_test_flow = imd_test.flow_from_directory(TEST_PATH, \n",
    "#                                              batch_size=300,\n",
    "#                                              class_mode='binary',\n",
    "#                                              target_size=target_size)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# # im = image.load_img(df_labels[df_labels.is_train].iloc[0]['file_name'],target_size=(300, 300))\n",
    "# # I = np.expand_dims(image.img_to_array(im), 0)\n",
    "\n",
    "t = []\n",
    "l = []\n",
    "for f  in df_labels[df_labels.is_train == False].file_name:\n",
    "    t.append(image.img_to_array(image.load_img(f, target_size=(150, 150))) * 1./255)\n",
    "    \n",
    "labs = df_labels[df_labels.is_train == False].label.tolist()    \n",
    "\n",
    "M = np.concatenate([np.expand_dims(z, axis=0) for z in t], axis=0)\n",
    "M.shape\n",
    "\n",
    "\n",
    "preds = model.predict_classes(M)\n",
    "\n",
    "\n",
    "ims = []\n",
    "for f  in df_labels[df_labels.is_train == False].iloc[np.where((real == preds.reshape(1, -1)[0]) == False)].file_name:\n",
    "    ims.append(image.load_img(f))\n",
    "    \n",
    "sum(real == preds.reshape(1, -1)[0]) / (len(real) * 1.)\n",
    "\n",
    "\n",
    "# ims[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 1, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(labs)\n",
    "real = le.transform(labs)\n",
    "real\n",
    "\n",
    "pred_y  = le.inverse_transform(preds)\n",
    "real_y = le.inverse_transform(real)\n",
    "pred_y\n",
    "real_y\n",
    "real\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder().fit(labs)\n",
    "label_encoder.inverse_transform(preds)\n",
    "# from pandas_ml import ConfusionMatrix\n",
    "# cm =  ConfusionMatrix(real_y, pred_y)\n",
    "# cm.plot(normalized=True, backend='seaborn', max_colors=30)\n",
    "# cm.classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 0.1808, 2: 0.38, 3: 0.03, 4: 0.2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(le.transform(le.classes_), le.classes_))\n",
    "\n",
    "{0: 1 , 1: 0.1808, 2: 0.38, 3: 0.03, 4: 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'back': 1.0,\n",
       " u'back-side': 0.18081180811808117,\n",
       " u'front': 0.3828125,\n",
       " u'front-side': 0.037361799466260011,\n",
       " u'side': 0.20588235294117646}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h5file.create_dataset('images_tf', (len(df),224,224,3), maxshape=(None,224,224,3), chunks=True, dtype=float)\n",
    "# h5file.create_dataset('labels', shape=(len(df),), dtype=\"S10\")\n",
    "\n",
    "# images_ds = h5file.get('images_tf')\n",
    "# labels_ds = h5file.get('labels')\n",
    "\n",
    "\n",
    "# model.predict(HDF5Matrix('cars4.h5','images_tf',start=0, end=10))\n",
    "\n",
    "dict(196/df_labels.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# resnet = ResNet50(include_top=False)\n",
    "# vgg19 = VGG19()\n",
    "\n",
    "\n",
    "def load_image_keras(image_path, gray=False, target_size=(300, 300)):\n",
    "        im = image.load_img(image_path, grayscale=gray, target_size=target_size)\n",
    "        imarray = image.img_to_array(im)\n",
    "        imarray = np.expand_dims(imarray, axis=0)\n",
    "        imarray = preprocess_input(imarray)\n",
    "        return imarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# im = load_image_keras(df_labels.file_name.iloc[0], target_size=(224, 224))\n",
    "\n",
    "\n",
    "ims = [load_image_keras(p, target_size=(224, 224)) for p in df_labels.file_name]\n",
    "imsconc = np.concatenate(ims, axis=0)\n",
    "\n",
    "# load_image_keras(df_labels.file_name.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = resnet.predict(imsconc)\n",
    "# preds = vgg19.predict(imsconcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1832, 2048)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preds.flatten().reshape(preds.shape[0], -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(2048, activation='relu', input_dim=2048))\n",
    "# # model.add(Dense(3024, activation='relu'))\n",
    "# # model.add(Dense(2024, activation='relu'))\n",
    "# # model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(df_labels.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X, y, validation_split=0.2, nb_epoch=75, verbose=1)\n",
    "\n",
    "# preds[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90489130434782605"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(oob_score=True, n_estimators=500, n_jobs=3)\n",
    "rfc.fit(X, df_labels.label)\n",
    "rfc.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds_resnet_full =resnet.predict(imsconc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# decode_predictions(preds_resnet_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# resnet_top = ResNet50(include_top=True)\n",
    "# decode_predictions(resnet_top.predict(imsconc[10:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "front-side    736\n",
       "back-side     736\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(100, input_dim=2048, init=\"uniform\", activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(30, init=\"uniform\", activation=\"relu\"))\n",
    "# model.add(Dense(20, init=\"uniform\", activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(10, init=\"uniform\", activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, init=\"uniform\", activation=\"sigmoid\"))\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# model.fit(X, y, validation_split=0.33, nb_epoch=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from predict import label_encoder, model\n",
    "from utils import load_image_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "back_side = '/home/i008/cars_train/00433.jpg'\n",
    "front_image = '/home/i008/cars_train/00433.jpg'\n",
    "\n",
    "im  = load_image_keras(front_image, target_size=(150, 150))\n",
    "im=im*1/255\n",
    "predictions = model.predict_classes(im)\n",
    "print(label_encoder.inverse_transform(predictions))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}